import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras import models
from tensorflow.keras.layers import Dense

# ---------------------------------------------------------------
# 1. DATA GENERATION
# ---------------------------------------------------------------

n_samples = 2000
a = 3
centers = [(-a, -a), (a, a), (a, -a), (-a, a), (0, 0)]

# Generate synthetic 2D data
X, y = make_blobs(n_samples=n_samples, centers=centers, shuffle=False, random_state=42)

# Map multiple centers into two main classes
y[y == 0] = 0
y[y == 1] = 0
y[y == 2] = 1
y[y == 3] = 1
y[y == 4] = 0

# Plot generated data
plt.figure(figsize=(6,6))
cmap = ListedColormap(['red', 'blue'])
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, s=30)
plt.title("Generated 2D Data (Two Classes)")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# ---------------------------------------------------------------
# 2. TRAIN/TEST SPLIT
# ---------------------------------------------------------------

X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)
input_shape = X_train.shape[1]  # number of features
num_classes = len(np.unique(y))

# ---------------------------------------------------------------
# 3. BUILD TENSORFLOW NEURAL NETWORK
# ---------------------------------------------------------------

clf = models.Sequential([
    Dense(10, activation='sigmoid', input_shape=(input_shape,)),
    Dense(10, activation='sigmoid'),
    Dense(10, activation='tanh'),
    Dense(20, activation='linear'),
    Dense(2, activation='tanh'),
    Dense(5, activation='tanh'),
    Dense(num_classes, activation='softmax')
])

clf.summary()

clf.compile(
    optimizer='rmsprop',
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=['accuracy']
)

# ---------------------------------------------------------------
# 4. TRAINING
# ---------------------------------------------------------------

history = clf.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=500,
    verbose=0
)

# ---------------------------------------------------------------
# 5. EVALUATION
# ---------------------------------------------------------------

pred_probs = clf.predict(X_test)
pred_classes = pred_probs.argmax(axis=1)

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, pred_classes))

print("\nClassification Report:")
print(classification_report(y_test, pred_classes))

test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=0)
print(f"\nTest Accuracy: {test_acc:.3f} | Test Loss: {test_loss:.3f}")

# ---------------------------------------------------------------
# 6. DECISION BOUNDARY VISUALIZATION
# ---------------------------------------------------------------

h = 0.05
x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# Predict on the grid
grid_preds = clf.predict(np.column_stack([xx.ravel(), yy.ravel()]))
Z = grid_preds.argmax(axis=1).reshape(xx.shape)

# Plot
plt.figure(figsize=(7,6))
cmap_bg = ListedColormap(['#FFAAAA', '#AAAAFF'])
cmap_points = ListedColormap(['red', 'blue'])

plt.contourf(xx, yy, Z, cmap=cmap_bg, alpha=0.6)
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolor='red', s=50, label='Train')
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, edgecolor='black', s=50, alpha=0.7, label='Test')

plt.title(f"Decision Boundary (Test Accuracy = {test_acc:.3f})")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.show()
