import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.datasets import make_blobs
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix, classification_report

# ---------------------------------------------------------------
# 1. DATA GENERATION
# ---------------------------------------------------------------

# Define number of samples and cluster centers
n_samples = 2000
a = 3
centers = [(-a, -a), (a, a), (a, -a), (-a, a), (0, 0)]

# Generate synthetic 2D data
X, y = make_blobs(n_samples=n_samples, centers=centers, shuffle=False, random_state=42)

# Combine multiple centers into two main classes
# (Group 0,1,4 → class 0) and (Group 2,3 → class 1)
y[y == 0] = 0
y[y == 1] = 0
y[y == 2] = 1
y[y == 3] = 1
y[y == 4] = 0

# Visualize the generated data
plt.figure(figsize=(6, 6))
cmap = ListedColormap(['red', 'blue'])
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap, s=30)
plt.title("Generated Data (Two Classes)")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

# ---------------------------------------------------------------
# 2. DATA SPLIT
# ---------------------------------------------------------------

X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.2, random_state=42
)

# ---------------------------------------------------------------
# 3. MODEL TRAINING (MLP Classifier)
# ---------------------------------------------------------------

clf = MLPClassifier(
    solver='lbfgs',
    hidden_layer_sizes=(20, 30, 40, 50),
    activation='tanh',
    alpha=1e-5,
    max_iter=1000,
    random_state=10
)

clf.fit(X_train, y_train)
predictions = clf.predict(X_test)

# ---------------------------------------------------------------
# 4. MODEL EVALUATION
# ---------------------------------------------------------------

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, predictions))

print("\nClassification Report:")
print(classification_report(y_test, predictions))

score = clf.score(X_test, y_test)
print(f"\nModel Accuracy: {score:.3f}")

# ---------------------------------------------------------------
# 5. VISUALIZATION OF DECISION BOUNDARY
# ---------------------------------------------------------------

# Create a mesh grid for plotting decision regions
h = 0.05
x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5
y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5
xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))

# Predict for each point on the grid
Z = clf.predict(np.column_stack([xx.ravel(), yy.ravel()]))
Z = Z.reshape(xx.shape)

# Plot the decision boundary
plt.figure(figsize=(7, 6))
cmap_bg = ListedColormap(['#FFAAAA', '#AAAAFF'])
cmap_points = ListedColormap(['red', 'blue'])

plt.contourf(xx, yy, Z, cmap=cmap_bg, alpha=0.6)
plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cmap_points, edgecolor='red', s=25, label="Train")
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cmap_points, edgecolor='black', s=25, label="Test")

plt.title(f"MLP Decision Boundary (Accuracy = {score:.3f})")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.show()
